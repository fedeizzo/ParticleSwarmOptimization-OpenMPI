@INPROCEEDINGS{KennedyEberhart,
  author={Kennedy, J. and Eberhart, R.},
  booktitle={Proceedings of ICNN'95 - International Conference on Neural Networks}, 
  title={Particle swarm optimization}, 
  year={1995},
  volume={4},
  number={},
  pages={1942-1948 vol.4},
  doi={10.1109/ICNN.1995.488968}
}


@InProceedings{NedJahMoraes,
    author="Nedjah, Nadia
    and de Moraes Calazan, Rog{\'e}rio
    and de Macedo Mourelle, Luiza",
    editor="Malyshkin, Victor",
    title="A Fine-Grained Parallel Particle Swarm Optimization on Many-core and Multi-core Architectures",
    booktitle="Parallel Computing Technologies",
    year="2017",
    publisher="Springer International Publishing",
    address="Cham",
    pages="215--224",
    abstract="Particle Swarm Optimization (PSO) is a stochastic metaheuristics yet very robust. Real-world optimizations require a high computational effort to converge to a viable solution. In general, parallel PSO implementations provide good performance, but this depends on the parallelization strategy as well as the number and/or characteristics of the exploited processors. In this paper, we propose a fine-grained paralellization strategy that focuses on the work done w.r.t. each of the problem dimensions and does it in parallel. Moreover, all particles act in parallel. This strategy is useful in computationally demanding optimization problems wherein the objective function has a very large number of dimensions. We map the computation onto three different parallel high-performance multiprocessor architectures, which are based on many and multi-core architectures. The performance of the proposed strategy is evaluated for four well-known benchmarks with high-dimension and different complexity. The obtained speedups are very promising.",
    isbn="978-3-319-62932-2"
}
@article{MoraesMitre,
  title = {A robust parallel algorithm of the particle swarm optimization method for large dimensional engineering problems},
  journal = {Applied Mathematical Modelling},
  volume = {39},
  number = {14},
  pages = {4223-4241},
  year = {2015},
  issn = {0307-904X},
  doi = {https://doi.org/10.1016/j.apm.2014.12.034},
  url = {https://www.sciencedirect.com/science/article/pii/S0307904X14007094},
  author = {Antonio O.S. Moraes and João F. Mitre and Paulo L.C. Lage and Argimiro R. Secchi},
  keywords = {Optimization, Particle swarm, MPI, Asynchronous parallelization, Parameter estimation, Convergence criterion},
  abstract = {The application of the Particle Swarm Optimization (PSO) method to large engineering problems is strongly limited by the required computational cost. This limitation comes from the large number of particles needed to optimize the many-variable function, the high computational cost of its evaluation and the lack of an adequate criteria to early detect the approach of the global optimum. The first two cost sources can be mitigated by an efficient parallel implementation of the PSO method but the last one need the development of a robust convergence criterion for the algorithm. This work develops an efficient and robust optimization method by using a new convergence criterion in an asynchronous parallel implementation of PSO. In the optimization of benchmark test functions, this method showed very good performance, with parallel efficiency between 80% and 100%, and excellent robustness, always detecting the global optimum. Finally, the method was successfully applied to an actual estimation problem with 81 parameters.}
}
